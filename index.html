<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0045)http://6.869.csail.mit.edu/fa19/schedule.html -->
<html xmlns="http://www.w3.org/1999/xhtml"><head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
<!--	<script async src="https://www.googletagmanager.com/gtag/js?id=G-WLX2Z5QLG8"></script>-->
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-WLX2Z5QLG8');
	</script>
	
	
	
	
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

<script type="text/javascript">
$(document).ready(function () {

    if (localStorage.getItem("my_app_name_here-quote-scroll") != null) {
        $(window).scrollTop(localStorage.getItem("my_app_name_here-quote-scroll"));
    }

    $(window).on("scroll", function() {
        localStorage.setItem("my_app_name_here-quote-scroll", $(window).scrollTop());
    });

  });
</script>
	
	
	
	
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
   <title>Splicing ViT Features for Semantic Appearance Transfer</title>
  <link href="style.css" rel="stylesheet" type="text/css">


  <meta name="description" content="Project page for &#39;Splicing ViT Features for Semantic Appearance Transfer.&#39;">
  <link rel="icon" href="./pics/wis_logo.jpg">
</head>
	
<body>
  <p class="title">Splicing ViT Features for Semantic Appearance Transfer</p>
  <table width="999" border="0" align="center" class="menu" style="margin-bottom: 8px;">
    <tbody>
      <tr>
        <td style="font-size: 17pt;" align="center">CVPR 2022 Oral</td>
      </tr>
    </tbody>
  </table>
<p class="author">
    <span class="author"><a target="_blank" href="https://www.linkedin.com/in/narek-tumanyan-5a3334122/">Narek Tumanyan</a>&nbsp;<sup>*</sup></span>
    <span class="author"><a target="_blank" href="https://omerbt.github.io/">Omer Bar-Tal&nbsp;</a><sup>*</sup></span>
	<span class="author"><a target="_blank" href="https://www.weizmann.ac.il/math/bagon/home">Shai Bagon</a>&nbsp;<sup>&nbsp;</sup></span>
    <span class="author"><a target="_blank" href="https://www.weizmann.ac.il/math/dekel/">Tali Dekel</a>&nbsp;<sup>&nbsp;</sup></span>
  </p>
  <table border="0" align="center" class="affiliations" width="1200px">
      <tbody align="center">
    <tr>
        <td style="text-align: right; width: 17%"><img src="./pics/wis_logo.jpg" height="48" alt=""></td>
        <td style="text-align: left; width:20%; ">&nbsp;<sup>&nbsp;</sup>&nbsp;<a href="https://www.weizmann.ac.il/pages/">Weizmann Institute of Science</a></td>
    </tr>
    </tbody></table>

    <table width="999" border="0" align="center" class="menu" style="margin-bottom: 8px;">
      <tbody>
        <tr>
          <td align="center">| <a href="#paper">Paper</a> | <a href="#sm">Supplementary Material</a> | <a href="https://github.com/omerbt/Splice" target="_blank">Code</a> | <a href="https://colab.research.google.com/github/omerbt/Splice/blob/master/Splice.ipynb" target="_blank">Colab</a> |</td>
        </tr>
      </tbody>
    </table>
<div class="container">
      <table width="1000" border="0" align="center">
        <tbody>
			<tr><img src="pics/teaser.jpg" alt="" width="1000" /></tr>
			<tr>
				<td style="text-align: left; width: 17%"><i>*Equal contribution.</i></td>
		  </tr>
		  <tr align="center"></tr>			
        </tbody></table>
	    &nbsp; 
		
  <p><span class="section"><b>Abstract</b></span> </p>
          <p> We present a method for semantically transferring the visual appearance of one natural image to another. 
Specifically, our goal is to generate an image in which objects in a source structure image are "painted" with the visual appearance of their semantically related objects in a target appearance image.  Our method works by training a generator given only a single  structure/appearance image pair as input. To integrate semantic information into our framework - a pivotal component in  tackling this task - our key idea is to leverage a pre-trained and fixed Vision Transformer (ViT) model which serves as an external semantic prior.  Specifically, we derive novel representations of structure and  appearance extracted from deep ViT features, untwisting them from the learned self-attention modules. We then establish an objective function that splices the desired  structure and appearance representations, interweaving them together in the space of ViT features. 
Our framework, which we term "Splice", does not involve adversarial training, nor does it require any additional input information such as semantic segmentation or correspondences, and can generate high resolution results, e.g., work in HD. We demonstrate high quality results on a variety of in-the-wild image pairs, under significant variations in the number of objects, their pose and appearance. &nbsp; </p>
		
  <p class="section">&nbsp;</p>
<p class="section"><b>Semantic Appearance Transfer Results</b></p>
<table align="center" width="940" border="0">
  <tbody>
    <tr>
      <td><p style="margin-top: 0px;">For each example, shown left-to-right: the target appearance image, the source structure image, and our result. The full set of results is included in the <a href="#sm">supplementary material</a>. Our model successfully manages to tranfer the appearance from the target appearance image to the source structure image in a semantically meaningful manner. Notice the variability in number of objects, pose, and the significant appearance changes between the images in each pair. </p></td>
    </tr>
    <tr>
      <td><img src="pics/results.jpg" alt="" width="1000" /></td>
    </tr>
  </tbody>
</table>
<p class="section">&nbsp;</p>

<p class="section"><b>CVPR 2022 Oral</b></p>
<table width="940" border="0">
  <tbody>
    <tr>
      <td><iframe width="100%" height="500px"
        src="https://www.youtube.com/embed/MpBdcfpGid0">
        </iframe></td>
    </tr>
  </tbody>
</table>

<p class="section">&nbsp;</p>
<p class="section" id="paper"><b>Paper</b></p>
<!-- <p class="subsection">CVPR Paper</p> -->
          <table width="940" border="0">
            <tbody>
              <tr><td style="font-weight: bold">CVPR Paper</td></tr>
              <tr>
                <td height="100"><a href="paper.pdf" target="_blank" rel="noopener noreferrer"><img src="./pics/paper_cover.jpg" alt="" width="140" height="167"></a></td>
                <td width="750"><p><b>Splicing ViT Features for Semantic Appearance Transfer</b><br>
                  Narek Tumanyan <sup>*</sup>, Omer Bar-Tal <sup>*</sup>, Shai Bagon, Tali Dekel.<br />
                  (* indicates equal contribution)                  <br>
                  <em>CVPR 2022 Oral.</em><br><br>
                   [<a href="https://arxiv.org/abs/2201.00424" target="_blank" rel="noopener noreferrer">paper</a>]</p>
                </td>
              </tr>
            </tbody>
          </table>
         
<br />

<!-- <p class="subsection">TOG Paper</p> -->
          <table width="940" border="0">
            <tbody>
              <tr><td style="font-weight: bold">Extended TOG Paper</td></tr>
              <tr>
                <td height="100"><a href="tog-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="./pics/paper-cover-tog.jpeg" alt="" width="140" height="167"></a></td>
                <td width="750"><p><b>Disentangling Structure and Appearance in ViT Feature Space</b><br>
                  Narek Tumanyan, Omer Bar-Tal, Shir Amir, Shai Bagon, Tali Dekel.<br />
                  <em>ACM Transactions on Graphics.</em><br><be>
	          [<a href="https://arxiv.org/abs/2311.12193" target="_blank" rel="noopener noreferrer">paper</a>]</p>
                </td>
              </tr>
            </tbody>
          </table>



          <p class="section">&nbsp;</p>
          <p class="section" id="sm"><b>Supplementary Material</b></p>
          <table width="587" height="136" border="0">
            <tbody>
              <tr>
                <td width="180"><img src="./pics/sm_illustration.png" alt="" height="150"></td>
                <td align="left">
                  <p>[<a href="./sm/index.html" target="_blank">supplementary page</a>]</p>
                </td>
              </tr>
            </tbody>
          </table>
          




	      <p class="section">&nbsp;</p>

          <p class="section" id="bibtex"><b>Bibtex</b></p>

          <p class="subsection" id="bibtex"><b>CVPR Paper:</b></p>

          <table border="0">
            <tbody>
              <pre style=" display: block;
  background: #eee;
  white-space: pre;
  -webkit-overflow-scrolling: touch;
  max-width: 100%;
  min-width: 100px;
  border-radius: 20px;
  padding: 0;;">

  @inproceedings{tumanyan2022splicing,
    title={Splicing ViT Features for Semantic Appearance Transfer},
    author={Tumanyan, Narek and Bar-Tal, Omer and Bagon, Shai and Dekel, Tali},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={10748--10757},
    year={2022}
  }
			  </pre>


            </tbody>
          </table>


          <p class="subsection" id="bibtex"><b>Extended TOG Paper:</b></p>

          <table border="0">
            <tbody>
              <pre style=" display: block;
  background: #eee;
  white-space: pre;
  -webkit-overflow-scrolling: touch;
  max-width: 100%;
  min-width: 100px;
  border-radius: 20px;
  padding: 0;;">

  @article{tumanyan2023disentangling,
    author = {Tumanyan, Narek and Bar-Tal, Omer and Amir, Shir and Bagon, Shai and Dekel, Tali},
    title = {Disentangling Structure and Appearance in ViT Feature Space},
    year = {2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    issn = {0730-0301},
    url = {https://doi.org/10.1145/3630096},
    doi = {10.1145/3630096},
    journal = {ACM Trans. Graph.},
    month = {nov},
    keywords = {Vision Transformers, Real-Time Style Transfer, Style Transfer, Feature Inversion}
    }
			  </pre>


            </tbody>
          </table>
        
          
	      <p class="section">&nbsp;</p>          
<!--          <p>&nbsp;</p>-->
  <p><b>Acknowledgments</b></p>
	<p>We would like to thank <a href="https://www.weizmann.ac.il/math/meirav/">Meirav Galun</a> for her insightful comments and discussion.
    We thank <a href="http://www.oliverwang.info/">Oliver Wang</a> and <a href="https://taesung.me/">Taesung Park</a> for their help with the comparison to Swapping Autoencoders.</p>
</div>


      
</body>
</html>
